"""
æ™ºèƒ½åœ†æŸ±ä½“ä¸­å¿ƒæ£€æµ‹å™¨
è‡ªåŠ¨è¯†åˆ«è§†è§’ï¼ˆç«¯é¢/ä¾§é¢ï¼‰å¹¶ä½¿ç”¨åˆé€‚çš„æ£€æµ‹æ–¹æ³•
"""

import cv2
import numpy as np
from typing import Tuple, Optional, Dict
import os


class SmartCylinderDetector:
    """æ™ºèƒ½åœ†æŸ±ä½“æ£€æµ‹å™¨ - è‡ªåŠ¨è¯†åˆ«è§†è§’"""
    
    def __init__(self):
        self.min_circle_radius = 20
        self.max_circle_radius = 1000
        self.min_contour_area = 500
        
        # å®šä¹‰å¸¸è§æ¡çº¹é¢œè‰²èŒƒå›´ï¼ˆHSVè‰²å½©ç©ºé—´ï¼‰
        self.color_ranges = {
            'black': {'lower': np.array([0, 0, 0]), 'upper': np.array([180, 255, 50])},
            'white': {'lower': np.array([0, 0, 200]), 'upper': np.array([180, 30, 255])},
            'yellow': {'lower': np.array([20, 100, 100]), 'upper': np.array([30, 255, 255])},
            'blue': {'lower': np.array([100, 100, 100]), 'upper': np.array([130, 255, 255])},
            'red': {'lower': np.array([0, 100, 100]), 'upper': np.array([10, 255, 255])},
            'green': {'lower': np.array([40, 40, 40]), 'upper': np.array([80, 255, 255])},
            'brown': {'lower': np.array([10, 50, 20]), 'upper': np.array([20, 255, 200])},
            'orange': {'lower': np.array([10, 100, 100]), 'upper': np.array([20, 255, 255])}
        }
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†å›¾åƒ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        return blurred
    
    def detect_circles(self, gray: np.ndarray) -> Optional[np.ndarray]:
        """æ£€æµ‹åœ†å½¢ï¼ˆç«¯é¢è§†å›¾ï¼‰- æ”¹è¿›ç‰ˆ"""
        # å°è¯•å¤šç»„å‚æ•°
        param_sets = [
            # (minDist, param1, param2, minRadius, maxRadius)
            (50, 100, 30, 20, 500),   # åŸå§‹å‚æ•°
            (40, 80, 25, 30, 400),    # æ›´å®½æ¾
            (60, 120, 35, 40, 600),   # æ›´ä¸¥æ ¼
            (30, 60, 20, 20, 300),    # æœ€å®½æ¾
        ]
        
        all_circles = []
        
        for minDist, param1, param2, minRadius, maxRadius in param_sets:
            circles = cv2.HoughCircles(
                gray,
                cv2.HOUGH_GRADIENT,
                dp=1,
                minDist=minDist,
                param1=param1,
                param2=param2,
                minRadius=minRadius,
                maxRadius=min(maxRadius, min(gray.shape) // 2)
            )
            
            if circles is not None:
                all_circles.extend(circles[0])
        
        if not all_circles:
            return None
        
        # å»é‡ï¼šåˆå¹¶ç›¸è¿‘çš„åœ†
        unique_circles = []
        all_circles = sorted(all_circles, key=lambda c: c[2], reverse=True)  # æŒ‰åŠå¾„æ’åº
        
        # å›¾åƒå°ºå¯¸
        max_dim = max(gray.shape)
        
        for circle in all_circles:
            cx, cy, r = circle
            
            # è¿‡æ»¤ä¸åˆç†çš„åœ†ï¼š
            # 1. åŠå¾„ä¸èƒ½å¤ªå¤§ï¼ˆè¶…è¿‡å›¾åƒ20%ï¼‰
            # 2. åœ†å¿ƒä¸èƒ½å¤ªé è¿‘è¾¹ç¼˜
            # 3. åŠå¾„ä¸èƒ½å¤ªå°ï¼ˆå°äº30pxï¼‰
            margin = max(r * 0.3, 50)  # è‡³å°‘50pxçš„è¾¹è·
            if (r > max_dim * 0.20 or  # åŠå¾„å¤ªå¤§ï¼ˆæ”¹ä¸º20%ï¼‰
                cx < margin or cy < margin or  # å¤ªé è¾¹
                cx > gray.shape[1] - margin or cy > gray.shape[0] - margin or
                r < 30):  # å¤ªå°
                continue
            
            is_duplicate = False
            
            for existing in unique_circles:
                ex, ey, er = existing
                dist = np.sqrt((cx - ex)**2 + (cy - ey)**2)
                
                # å¦‚æœåœ†å¿ƒå¾ˆæ¥è¿‘ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªåœ†
                if dist < min(r, er) * 0.5:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_circles.append(circle)
        
        if not unique_circles:
            return None
        
        # è¿”å›ä¸ºéœå¤«åœ†å˜æ¢æ ¼å¼
        return np.array([unique_circles], dtype=np.float32)
    
    def detect_rectangle_contours(self, image: np.ndarray, gray: np.ndarray) -> Tuple[Optional[np.ndarray], Dict]:
        """æ£€æµ‹çŸ©å½¢è½®å»“ï¼ˆä¾§é¢è§†å›¾ï¼‰- æ”¹è¿›ç‰ˆï¼Œé¿å…æ£€æµ‹èƒŒæ™¯"""
        h, w = gray.shape
        image_area = h * w
        
        # å¤šç§äºŒå€¼åŒ–æ–¹æ³•
        methods = []
        
        # æ–¹æ³•1: Otsué˜ˆå€¼ï¼ˆæ­£å‘å’Œåå‘ï¼‰
        _, binary1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        methods.append(('otsu_inv', binary1))
        
        _, binary1_normal = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        methods.append(('otsu_normal', binary1_normal))
        
        # æ–¹æ³•2: è‡ªé€‚åº”é˜ˆå€¼
        binary2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY_INV, 11, 2)
        methods.append(('adaptive_inv', binary2))
        
        # æ–¹æ³•3: Cannyè¾¹ç¼˜
        edges = cv2.Canny(gray, 30, 100)
        # è†¨èƒ€è¾¹ç¼˜ä»¥å½¢æˆé—­åˆè½®å»“
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        edges = cv2.dilate(edges, kernel, iterations=2)
        methods.append(('canny', edges))
        
        best_contour = None
        best_score = 0
        best_method = None
        
        for method_name, binary in methods:
            # å½¢æ€å­¦æ“ä½œ
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
            binary_processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
            binary_processed = cv2.morphologyEx(binary_processed, cv2.MORPH_OPEN, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(binary_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # è¿‡æ»¤æ¡ä»¶
                if area < self.min_contour_area:
                    continue
                
                # æ’é™¤å æ®æ•´ä¸ªå›¾åƒçš„è½®å»“ï¼ˆå¯èƒ½æ˜¯èƒŒæ™¯ï¼‰
                area_ratio = area / image_area
                if area_ratio > 0.7:  # å¦‚æœå æ®è¶…è¿‡70%çš„å›¾åƒï¼Œè‚¯å®šæ˜¯èƒŒæ™¯
                    continue
                
                # æ’é™¤ä¸­ç­‰å¤§ä½†å¯èƒ½æ˜¯èƒŒæ™¯çš„è½®å»“
                if area_ratio > 0.25:  # å 25%-70%ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥
                    # å¦‚æœæ˜¯å¤§è½®å»“ä¸”è´´è¿‘è¾¹ç¼˜ï¼Œå¾ˆå¯èƒ½æ˜¯èƒŒæ™¯
                    margin = 20
                    if (x < margin or y < margin or 
                        x + w > image.shape[1] - margin or 
                        y + h > image.shape[0] - margin):
                        continue  # å¤§ä¸”è´´è¾¹ï¼Œæ˜¯èƒŒæ™¯
                
                # è®¡ç®—è¾¹ç•Œæ¡†
                x, y, w, h = cv2.boundingRect(contour)
                
                # æ’é™¤è´´è¾¹çš„å¤§è½®å»“ï¼ˆå¯èƒ½æ˜¯èƒŒæ™¯/ç™½çº¸ï¼‰
                margin = 10
                if (x < margin and y < margin and 
                    x + w > image.shape[1] - margin and 
                    y + h > image.shape[0] - margin):
                    continue  # å››è¾¹éƒ½è´´è¾¹ï¼Œå¯èƒ½æ˜¯èƒŒæ™¯
                
                rect_area = w * h
                rectangularity = area / rect_area if rect_area > 0 else 0
                aspect_ratio = max(w, h) / (min(w, h) + 1e-5)
                
                # è®¡ç®—å‘¨é•¿
                perimeter = cv2.arcLength(contour, True)
                
                # è®¡ç®—ç´§å‡‘åº¦ï¼ˆè¶Šæ¥è¿‘1è¶Šè§„åˆ™ï¼‰
                if perimeter > 0:
                    compactness = (4 * np.pi * area) / (perimeter * perimeter)
                else:
                    compactness = 0
                
                # ç»¼åˆè¯„åˆ†æ”¹è¿›v2ï¼š
                # é‡ç‚¹ï¼šæ­£ç¡®è¯†åˆ«é•¿æ¡å½¢åœ†æŸ±ä½“ï¼ˆå¦‚p3ï¼‰å’Œæ­£æ–¹å½¢åœ†æŸ±ä½“ï¼ˆå¦‚p1ï¼‰
                
                # é¢ç§¯åˆ†æ•°ï¼šä¼˜å…ˆ5%-25%çš„ä¸­ç­‰é¢ç§¯
                if 0.05 < area_ratio < 0.20:
                    area_score = 2.0  # æœ€ä½³èŒƒå›´
                elif 0.02 < area_ratio < 0.05:
                    area_score = 1.2  # ç¨å°ä½†å¯æ¥å—
                elif 0.20 < area_ratio < 0.30:
                    area_score = 0.8  # åå¤§
                else:
                    area_score = 0.2  # å¤ªå°(<2%)æˆ–å¤ªå¤§(>30%)
                
                # å½¢çŠ¶åˆ†æ•°ï¼šé’ˆå¯¹ä¸åŒå®½é«˜æ¯”
                if 0.8 < aspect_ratio < 1.5:
                    shape_score = 3.0  # æ¥è¿‘æ­£æ–¹å½¢ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼ˆp1ç±»å‹ï¼‰
                elif 2.0 < aspect_ratio < 4.0:
                    shape_score = 2.5  # é•¿æ¡å½¢ï¼Œä¼˜å…ˆçº§å¾ˆé«˜ï¼ˆp3ç±»å‹ï¼‰
                elif 1.5 < aspect_ratio < 2.0:
                    shape_score = 2.0  # ç¨é•¿
                elif 4.0 < aspect_ratio < 8.0:
                    shape_score = 1.5  # å¾ˆé•¿çš„æ¡å½¢
                else:
                    shape_score = 0.5  # å¤ªæç«¯
                
                # çŸ©å½¢åº¦åˆ†æ•°ï¼šå¿…é¡»å¤§äº0.4æ‰è€ƒè™‘
                if rectangularity < 0.4:
                    rect_score = 0.1  # å¤ªä¸è§„åˆ™
                else:
                    rect_score = rectangularity ** 1.5
                
                # ç´§å‡‘åº¦åˆ†æ•°
                compact_score = 1.0 + compactness * 0.3
                
                # ç»¼åˆåˆ†æ•°ï¼ˆä½¿ç”¨é¢ç§¯å¼€æ–¹é™ä½å¤§è½®å»“ä¼˜åŠ¿ï¼‰
                score = (area ** 0.6) * rect_score * area_score * shape_score * compact_score
                
                if score > best_score:
                    best_score = score
                    best_contour = contour
                    best_method = method_name
        
        info = {
            'method': best_method,
            'score': best_score
        }
        
        return best_contour, info
    
    def calculate_contour_center(self, contour: np.ndarray) -> Tuple[int, int]:
        """è®¡ç®—è½®å»“çš„ä¸­å¿ƒç‚¹ - ä½¿ç”¨è¾¹ç•Œæ¡†ä¸­å¿ƒï¼ˆæ›´ç¨³å®šï¼‰"""
        # å¯¹äºçŸ©å½¢ç‰©ä½“ï¼Œè¾¹ç•Œæ¡†çš„å‡ ä½•ä¸­å¿ƒæ¯”è´¨å¿ƒæ›´å‡†ç¡®
        x, y, w, h = cv2.boundingRect(contour)
        cx = x + w // 2
        cy = y + h // 2
        return cx, cy
    
    def detect_orientation(self, contour: np.ndarray) -> str:
        """æ£€æµ‹æ–¹å‘"""
        x, y, w, h = cv2.boundingRect(contour)
        if w > h * 1.2:
            return "horizontal"
        elif h > w * 1.2:
            return "vertical"
        else:
            return "square"
    
    def detect_stripe_colors(self, image: np.ndarray, contour: np.ndarray = None, 
                            circle_info: tuple = None) -> Dict:
        """
        æ£€æµ‹æ¡çº¹é¢œè‰²
        
        Args:
            image: åŸå§‹BGRå›¾åƒ
            contour: è½®å»“ï¼ˆä¾§é¢è§†å›¾ï¼‰
            circle_info: (x, y, radius) åœ†å½¢ä¿¡æ¯ï¼ˆç«¯é¢è§†å›¾ï¼‰
        
        Returns:
            åŒ…å«æ£€æµ‹åˆ°çš„é¢œè‰²ä¿¡æ¯çš„å­—å…¸
        """
        # è·å–æ„Ÿå…´è¶£åŒºåŸŸ
        if contour is not None:
            # ä¾§é¢è§†å›¾ï¼šä½¿ç”¨è½®å»“åŒºåŸŸ
            x, y, w, h = cv2.boundingRect(contour)
            roi = image[y:y+h, x:x+w]
        elif circle_info is not None:
            # ç«¯é¢è§†å›¾ï¼šä½¿ç”¨åœ†å½¢åŒºåŸŸ
            cx, cy, radius = circle_info
            x = max(0, int(cx - radius))
            y = max(0, int(cy - radius))
            w = int(radius * 2)
            h = int(radius * 2)
            roi = image[y:y+h, x:x+w]
        else:
            # ä½¿ç”¨æ•´ä¸ªå›¾åƒ
            roi = image
        
        if roi.size == 0:
            return {'colors': [], 'dominant_color': None}
        
        # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        
        # æ£€æµ‹æ¯ç§é¢œè‰²
        color_percentages = {}
        total_pixels = roi.shape[0] * roi.shape[1]
        
        for color_name, color_range in self.color_ranges.items():
            # åˆ›å»ºé¢œè‰²æ©ç 
            mask = cv2.inRange(hsv, color_range['lower'], color_range['upper'])
            
            # è®¡ç®—é¢œè‰²å æ¯”
            color_pixels = np.sum(mask > 0)
            percentage = (color_pixels / total_pixels) * 100
            
            if percentage > 5:  # åªè®°å½•å æ¯”è¶…è¿‡5%çš„é¢œè‰²
                color_percentages[color_name] = percentage
        
        # ç‰¹æ®Šå¤„ç†çº¢è‰²ï¼ˆè·¨è¶ŠHSVè‰²è½®ï¼‰
        if 'red' in self.color_ranges:
            mask1 = cv2.inRange(hsv, np.array([0, 100, 100]), np.array([10, 255, 255]))
            mask2 = cv2.inRange(hsv, np.array([170, 100, 100]), np.array([180, 255, 255]))
            red_mask = cv2.bitwise_or(mask1, mask2)
            red_pixels = np.sum(red_mask > 0)
            red_percentage = (red_pixels / total_pixels) * 100
            if red_percentage > 5:
                color_percentages['red'] = red_percentage
        
        # æ¡çº¹é¢œè‰²ï¼ˆæ’é™¤çº¸ç­’æœ¬è‰²ï¼‰
        # å½©è‰²æ¡çº¹ï¼šé»„è‰²ã€è“è‰²ã€çº¢è‰²ã€ç»¿è‰²ï¼ˆå æ¯”>8%ï¼‰
        # é»‘è‰²æ¡çº¹ï¼šé»‘è‰²ï¼ˆå æ¯”>15%ï¼Œé¿å…è¯¯åˆ¤é˜´å½±ï¼‰
        color_stripe_colors = ['yellow', 'blue', 'red', 'green']
        black_stripe_colors = ['black']
        
        # ä¿ç•™å½©è‰²æ¡çº¹å’Œé»‘è‰²æ¡çº¹
        stripe_color_percentages = {}
        for color_name, percentage in color_percentages.items():
            if color_name in color_stripe_colors and percentage > 8:
                stripe_color_percentages[color_name] = percentage
            elif color_name in black_stripe_colors and percentage > 15:
                stripe_color_percentages[color_name] = percentage
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ¡çº¹ï¼Œè¿”å›ç©ºç»“æœ
        if not stripe_color_percentages:
            return {
                'colors': [],
                'colors_cn': [],
                'dominant_color': None,
                'dominant_color_cn': None,
                'has_stripes': False
            }
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰é¢œè‰²ï¼Œè¿”å›ç©ºç»“æœ
        if not stripe_color_percentages:
            return {
                'colors': [],
                'colors_cn': [],
                'dominant_color': None,
                'dominant_color_cn': None,
                'has_stripes': False
            }
        
        # æŒ‰å æ¯”æ’åº
        sorted_colors = sorted(stripe_color_percentages.items(), key=lambda x: x[1], reverse=True)
        
        # è·å–ä¸»è¦é¢œè‰²
        dominant_color = sorted_colors[0][0] if sorted_colors else None
        
        # ä¸­æ–‡é¢œè‰²åç§°æ˜ å°„
        color_names_cn = {
            'black': 'é»‘è‰²',
            'white': 'ç™½è‰²',
            'yellow': 'é»„è‰²',
            'blue': 'è“è‰²',
            'red': 'çº¢è‰²',
            'green': 'ç»¿è‰²'
        }
        
        # è½¬æ¢ä¸ºä¸­æ–‡åç§°
        colors_cn = [(color_names_cn.get(c, c), p) for c, p in sorted_colors]
        
        return {
            'colors': sorted_colors,
            'colors_cn': colors_cn,
            'dominant_color': dominant_color,
            'dominant_color_cn': color_names_cn.get(dominant_color, dominant_color) if dominant_color else None,
            'has_stripes': True
        }
    
    def process_image(self, image: np.ndarray) -> Tuple[np.ndarray, Dict]:
        """
        æ™ºèƒ½å¤„ç†å›¾åƒ
        è‡ªåŠ¨åˆ¤æ–­æ˜¯åœ†å½¢ï¼ˆç«¯é¢ï¼‰è¿˜æ˜¯çŸ©å½¢ï¼ˆä¾§é¢ï¼‰è§†å›¾
        """
        result_image = image.copy()
        gray = self.preprocess_image(image)
        
        # å°è¯•åœ†å½¢æ£€æµ‹
        circles = self.detect_circles(gray)
        
        # å°è¯•çŸ©å½¢è½®å»“æ£€æµ‹
        best_contour, contour_info = self.detect_rectangle_contours(image, gray)
        
        # å†³ç­–ï¼šä½¿ç”¨å“ªç§æ–¹æ³•
        circle_detected = circles is not None and len(circles[0]) > 0
        contour_detected = best_contour is not None
        
        if not circle_detected and not contour_detected:
            return result_image, {"error": "æœªæ£€æµ‹åˆ°åœ†æŸ±ä½“"}
        
        # æ™ºèƒ½å†³ç­–
        use_circle = False
        
        if circle_detected and contour_detected:
            # ä¸¤ç§éƒ½æ£€æµ‹åˆ°ï¼Œéœ€è¦åˆ¤æ–­å“ªä¸ªæ›´å¯é 
            circle = circles[0][0]
            circle_x, circle_y, circle_radius = circle[0], circle[1], circle[2]
            circle_area = np.pi * circle_radius ** 2
            contour_area = cv2.contourArea(best_contour)
            
            # è®¡ç®—è½®å»“çš„å®½é«˜æ¯”
            x, y, w, h = cv2.boundingRect(best_contour)
            aspect_ratio = max(w, h) / (min(w, h) + 1e-5)
            
            # è®¡ç®—è½®å»“å å›¾åƒçš„æ¯”ä¾‹
            image_area = gray.shape[0] * gray.shape[1]
            contour_ratio = contour_area / image_area
            circle_ratio = circle_area / image_area
            
            min_image_dim = min(gray.shape[0], gray.shape[1])
            
            # æ–°çš„å†³ç­–é€»è¾‘ï¼š
            # å¦‚æœè½®å»“çš„å®½é«˜æ¯”æ¥è¿‘1ï¼ˆæ­£æ–¹å½¢ï¼‰ï¼Œä¸”é¢ç§¯åˆç†ï¼ˆ3%-15%ï¼‰ï¼Œ
            # å¾ˆå¯èƒ½æ˜¯åœ†æŸ±ä½“çš„ä¾§é¢è§†å›¾ï¼ˆæ°´å¹³æ”¾ç½®ï¼‰
            # è¿™ç§æƒ…å†µä¸‹è½®å»“æ£€æµ‹æ›´å¯é 
            
            # æ¡ä»¶1ï¼šè½®å»“æ¥è¿‘æ­£æ–¹å½¢ä¸”é¢ç§¯åˆç† -> ä¼˜å…ˆä½¿ç”¨è½®å»“
            if 0.8 < aspect_ratio < 1.5 and 0.02 < contour_ratio < 0.15:
                use_circle = False
                
            # æ¡ä»¶2ï¼šæ˜æ˜¾çš„é•¿æ¡å½¢ -> ä¾§é¢è§†å›¾ï¼Œç”¨è½®å»“
            elif aspect_ratio > 2.0 and 0.05 < contour_ratio < 0.8:
                use_circle = False
                
            # æ¡ä»¶3ï¼šåœ†å½¢åŠå¾„å¤ªå¤§ -> å¯èƒ½è¯¯æ£€ï¼Œç”¨è½®å»“
            elif circle_radius > min_image_dim * 0.2:
                use_circle = False
                
            # æ¡ä»¶4ï¼šåœ†å½¢å¾ˆå°ä½†è½®å»“å¾ˆå¤§ -> ç”¨è½®å»“
            elif circle_radius < 100 and contour_area > circle_area * 1.5:
                use_circle = False
                
            # æ¡ä»¶5ï¼šè½®å»“å¾ˆå°ä½†åœ†å½¢åˆç† -> ç«¯é¢è§†å›¾
            elif contour_ratio < 0.02 and 100 < circle_radius < min_image_dim * 0.18:
                use_circle = True
                
            # æ¡ä»¶6ï¼šåœ†å½¢åˆç†ä¸”è½®å»“æ¯”ä¾‹ä¸æ˜¯ç‰¹åˆ«åˆé€‚ -> ç«¯é¢è§†å›¾
            elif 100 < circle_radius < min_image_dim * 0.18 and (contour_ratio > 0.3 or contour_ratio < 0.01):
                use_circle = True
                
            # é»˜è®¤ï¼šä½¿ç”¨è½®å»“ï¼ˆä¾§é¢è§†å›¾æ›´å¸¸è§ï¼‰
            else:
                use_circle = False
                
        elif circle_detected:
            # åªæ£€æµ‹åˆ°åœ†å½¢ï¼Œæ£€æŸ¥æ˜¯å¦åˆç†
            circle = circles[0][0]
            circle_radius = circle[2]
            min_image_dim = min(gray.shape[0], gray.shape[1])
            
            # åœ†å½¢åŠå¾„ä¸èƒ½å¤ªå¤§æˆ–å¤ªå°
            if 40 < circle_radius < min_image_dim * 0.2:
                use_circle = True
            else:
                return result_image, {"error": "æœªæ£€æµ‹åˆ°åˆé€‚çš„åœ†æŸ±ä½“"}
        else:
            use_circle = False
        
        # æ ¹æ®å†³ç­–è¿”å›ç»“æœ
        if use_circle:
            # ä½¿ç”¨åœ†å½¢æ£€æµ‹ç»“æœ
            circles = np.uint16(np.around(circles))
            # é€‰æ‹©æœ€å¤§çš„åœ†
            max_circle = max(circles[0], key=lambda c: c[2])
            
            # ç«¯é¢è§†å›¾ä¸æ£€æµ‹é¢œè‰²ï¼ˆå†…éƒ¨é»‘è‰²æ˜¯ç©ºæ´ä¸æ˜¯æ¡çº¹ï¼‰
            color_info = {
                'colors': [],
                'colors_cn': [],
                'dominant_color': None,
                'dominant_color_cn': None,
                'has_stripes': False
            }
            
            info = {
                "type": "circle",
                "center": (int(max_circle[0]), int(max_circle[1])),
                "radius": int(max_circle[2]),
                "view": "ç«¯é¢è§†å›¾ (End View)",
                "num_circles": len(circles[0]),
                "color_info": color_info
            }
        else:
            # ä½¿ç”¨è½®å»“æ£€æµ‹ç»“æœ
            cx, cy = self.calculate_contour_center(best_contour)
            x, y, w, h = cv2.boundingRect(best_contour)
            orientation = self.detect_orientation(best_contour)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ¥è¿‘æ­£æ–¹å½¢çš„å½¢çŠ¶ï¼ˆå¯èƒ½æ˜¯åœ†å½¢ç«¯é¢ï¼‰
            # å¦‚æœå®½é«˜æ¯”æ¥è¿‘1ï¼Œè·³è¿‡é¢œè‰²æ£€æµ‹
            aspect_ratio = max(w, h) / (min(w, h) + 1e-5)
            if aspect_ratio < 1.3:
                # æ¥è¿‘æ­£æ–¹å½¢ï¼Œå¯èƒ½æ˜¯ç«¯é¢è§†å›¾ï¼Œè·³è¿‡é¢œè‰²æ£€æµ‹
                color_info = {
                    'colors': [],
                    'colors_cn': [],
                    'dominant_color': None,
                    'dominant_color_cn': None,
                    'has_stripes': False
                }
            else:
                # æ£€æµ‹é¢œè‰²ï¼ˆåªé’ˆå¯¹ä¾§é¢è§†å›¾ï¼‰
                color_info = self.detect_stripe_colors(image, contour=best_contour)
            
            info = {
                "type": "rectangle",
                "center": (cx, cy),
                "contour": best_contour,
                "bounding_box": (x, y, w, h),
                "orientation": orientation,
                "view": f"ä¾§é¢è§†å›¾ (Side View - {orientation})",
                "method": contour_info['method'],
                "area": cv2.contourArea(best_contour),
                "color_info": color_info
            }
        
        return result_image, info
    
    def visualize(self, image: np.ndarray, info: Dict) -> np.ndarray:
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        result = image.copy()
        
        if "error" in info:
            cv2.putText(result, info["error"], (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            return result
        
        cx, cy = info['center']
        
        if info['type'] == 'circle':
            # åœ†å½¢æ£€æµ‹å¯è§†åŒ–
            radius = info['radius']
            
            # ç»˜åˆ¶åœ†å½¢è½®å»“
            cv2.circle(result, (cx, cy), radius, (0, 255, 0), 3)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(result, (cx, cy), 8, (0, 0, 255), -1)
            cv2.circle(result, (cx, cy), 12, (255, 0, 0), 2)
            
            # ç»˜åˆ¶åå­—çº¿
            cross_length = min(50, radius // 2)
            cv2.line(result, (cx - cross_length, cy), (cx + cross_length, cy), (255, 0, 0), 3)
            cv2.line(result, (cx, cy - cross_length), (cx, cy + cross_length), (255, 0, 0), 3)
            
            # ç»˜åˆ¶ç›´å¾„çº¿
            for angle in [0, 45, 90, 135]:
                rad = np.radians(angle)
                x1 = int(cx + radius * np.cos(rad))
                y1 = int(cy + radius * np.sin(rad))
                x2 = int(cx - radius * np.cos(rad))
                y2 = int(cy - radius * np.sin(rad))
                cv2.line(result, (x1, y1), (x2, y2), (255, 255, 0), 1)
            
            # æ–‡æœ¬ä¿¡æ¯
            texts = [
                f"View: {info['view']}",
                f"Center: ({cx}, {cy})",
                f"Radius: {radius} px",
                f"Diameter: {radius * 2} px"
            ]
            
            # æ·»åŠ é¢œè‰²ä¿¡æ¯ï¼ˆåªæœ‰æ£€æµ‹åˆ°æ¡çº¹æ—¶æ‰æ˜¾ç¤ºï¼‰
            if 'color_info' in info and info['color_info'].get('has_stripes', False):
                colors_str = ", ".join([c for c, _ in info['color_info']['colors'][:3]])
                texts.append(f"Colors: {colors_str}")
        
        else:
            # çŸ©å½¢æ£€æµ‹å¯è§†åŒ–
            x, y, w, h = info['bounding_box']
            contour = info['contour']
            
            # ç»˜åˆ¶è½®å»“
            cv2.drawContours(result, [contour], -1, (0, 255, 0), 3)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result, (x, y), (x + w, y + h), (255, 0, 255), 2)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(result, (cx, cy), 10, (0, 0, 255), -1)
            cv2.circle(result, (cx, cy), 15, (255, 0, 0), 3)
            
            # ç»˜åˆ¶åå­—çº¿ï¼ˆç©¿è¿‡æ•´ä¸ªå›¾åƒï¼‰
            cv2.line(result, (0, cy), (result.shape[1], cy), (255, 0, 0), 2)
            cv2.line(result, (cx, 0), (cx, result.shape[0]), (255, 0, 0), 2)
            
            # ç»˜åˆ¶å±€éƒ¨åå­—çº¿
            cross_length = 40
            cv2.line(result, (cx - cross_length, cy), (cx + cross_length, cy), (0, 255, 255), 3)
            cv2.line(result, (cx, cy - cross_length), (cx, cy + cross_length), (0, 255, 255), 3)
            
            # æ–‡æœ¬ä¿¡æ¯
            texts = [
                f"View: {info['view']}",
                f"Center: ({cx}, {cy})",
                f"Size: {w}x{h} px",
                f"Area: {int(info['area'])} px^2",
                f"Method: {info['method']}"
            ]
            
            # æ·»åŠ é¢œè‰²ä¿¡æ¯ï¼ˆåªæœ‰æ£€æµ‹åˆ°æ¡çº¹æ—¶æ‰æ˜¾ç¤ºï¼‰
            if 'color_info' in info and info['color_info'].get('has_stripes', False):
                colors_str = ", ".join([c for c, _ in info['color_info']['colors'][:3]])
                texts.append(f"Colors: {colors_str}")
        
        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯å’Œæ–‡å­—
        text_y = 40
        for text in texts:
            (text_width, text_height), baseline = cv2.getTextSize(
                text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
            cv2.rectangle(result, (5, text_y - text_height - 8), 
                         (20 + text_width, text_y + baseline), (0, 0, 0), -1)
            cv2.putText(result, text, (10, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            text_y += 40
        
        return result


def process_single_image(image_path: str, output_dir: str = "data/output/center"):
    """å¤„ç†å•å¼ å›¾åƒ"""
    os.makedirs(output_dir, exist_ok=True)
    
    # è¯»å–å›¾åƒï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return None
    
    print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")
    print(f"   å›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = SmartCylinderDetector()
    
    # å¤„ç†å›¾åƒ
    _, info = detector.process_image(image)
    
    # å¯è§†åŒ–
    visualized = detector.visualize(image, info)
    
    # æ‰“å°æ£€æµ‹ä¿¡æ¯
    if "error" in info:
        print(f"   âŒ {info['error']}")
        return None
    else:
        cx, cy = info['center']
        view_type = info['type']
        view_name = info['view']
        
        print(f"   âœ… æ£€æµ‹æˆåŠŸ!")
        print(f"   ğŸ” è§†å›¾ç±»å‹: {view_name}")
        print(f"   ğŸ“ ä¸­å¿ƒåæ ‡: ({cx}, {cy})")
        
        if view_type == 'circle':
            print(f"   ğŸ“ åŠå¾„: {info['radius']} åƒç´ ")
            print(f"   ğŸ“ ç›´å¾„: {info['radius'] * 2} åƒç´ ")
        else:
            x, y, w, h = info['bounding_box']
            print(f"   ğŸ“ è¾¹ç•Œæ¡†: ({x}, {y}) - å°ºå¯¸: {w}x{h}")
            print(f"   ğŸ“ æ–¹å‘: {info['orientation']}")
            print(f"   ğŸ“Š é¢ç§¯: {int(info['area'])} åƒç´ Â²")
    
    # ä¿å­˜ç»“æœ
    filename = os.path.splitext(os.path.basename(image_path))[0]
    output_path = os.path.join(output_dir, f"{filename}_smart_result.jpg")
    
    is_success, buffer = cv2.imencode('.jpg', visualized)
    if is_success:
        buffer.tofile(output_path)
        print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æ˜¾ç¤ºç»“æœ
    display_height = 800
    aspect_ratio = image.shape[1] / image.shape[0]
    display_width = int(display_height * aspect_ratio)
    
    display_image = cv2.resize(visualized, (display_width, display_height))
    cv2.imshow("Smart Detection Result (Press any key to close)", display_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    return info


def batch_process(input_dir: str = "data/input", output_dir: str = "data/output/center"):
    """æ‰¹é‡å¤„ç†"""
    from pathlib import Path
    
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(input_dir).glob(f"*{ext}"))
        image_files.extend(Path(input_dir).glob(f"*{ext.upper()}"))
    
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    print("=" * 70)
    
    detector = SmartCylinderDetector()
    os.makedirs(output_dir, exist_ok=True)
    
    success_count = 0
    fail_count = 0
    results = []
    
    for idx, image_path in enumerate(image_files, 1):
        print(f"\n[{idx}/{len(image_files)}] å¤„ç†: {image_path.name}")
        
        image = cv2.imdecode(np.fromfile(str(image_path), dtype=np.uint8), cv2.IMREAD_COLOR)
        
        if image is None:
            print(f"   âŒ æ— æ³•è¯»å–å›¾åƒ")
            fail_count += 1
            continue
        
        _, info = detector.process_image(image)
        visualized = detector.visualize(image, info)
        
        # ä¿å­˜ç»“æœ
        output_path = os.path.join(output_dir, f"{image_path.stem}_smart_result.jpg")
        is_success, buffer = cv2.imencode('.jpg', visualized)
        if is_success:
            buffer.tofile(output_path)
        
        if "error" in info:
            print(f"   âŒ {info['error']}")
            fail_count += 1
        else:
            cx, cy = info['center']
            view_type = info['type']
            view_name = info['view']
            
            print(f"   âœ… {view_name}")
            print(f"      ä¸­å¿ƒ: ({cx}, {cy})")
            
            success_count += 1
            
            result_data = {
                'file': image_path.name,
                'view': view_name,
                'center_x': cx,
                'center_y': cy,
                'type': view_type
            }
            
            if view_type == 'circle':
                result_data['radius'] = info['radius']
                result_data['diameter'] = info['radius'] * 2
            else:
                x, y, w, h = info['bounding_box']
                result_data['width'] = w
                result_data['height'] = h
                result_data['orientation'] = info['orientation']
            
            results.append(result_data)
    
    print("\n" + "=" * 70)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ!")
    print(f"   âœ… æˆåŠŸ: {success_count}")
    print(f"   âŒ å¤±è´¥: {fail_count}")
    print(f"   ğŸ’¾ ç»“æœä¿å­˜åœ¨: {output_dir}")
    
    # ä¿å­˜CSVæŠ¥å‘Š
    if results:
        csv_path = os.path.join(output_dir, "smart_detection_report.csv")
        with open(csv_path, 'w', encoding='utf-8-sig') as f:
            f.write("æ–‡ä»¶å,è§†å›¾ç±»å‹,ä¸­å¿ƒX,ä¸­å¿ƒY,åŠå¾„,ç›´å¾„,å®½åº¦,é«˜åº¦,æ–¹å‘\n")
            for r in results:
                radius = r.get('radius', '')
                diameter = r.get('diameter', '')
                width = r.get('width', '')
                height = r.get('height', '')
                orientation = r.get('orientation', '')
                f.write(f"{r['file']},{r['view']},{r['center_x']},{r['center_y']},{radius},{diameter},{width},{height},{orientation}\n")
        print(f"   ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {csv_path}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("=" * 70)
        print("ğŸ” æ™ºèƒ½åœ†æŸ±ä½“ä¸­å¿ƒæ£€æµ‹å·¥å…·")
        print("=" * 70)
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python smart_detector.py <image_path>          # å¤„ç†å•å¼ å›¾åƒ")
        print("  python smart_detector.py --batch               # æ‰¹é‡å¤„ç†")
        print("\nç¤ºä¾‹:")
        print("  python smart_detector.py \"data/input/p(1).jpg\"")
        print("  python smart_detector.py --batch")
    elif sys.argv[1] == "--batch" or sys.argv[1] == "-b":
        batch_process()
    else:
        process_single_image(sys.argv[1])
