"""
æ ¹æ®ä¸¤ç«¯æˆªé¢åˆ¤æ–­åœ†æŸ±ä½“çš„é¦–å°¾
å‡è®¾ï¼šå­˜åœ¨æ˜æ˜¾æ¡çº¹çš„ä¸ºå¤´éƒ¨ï¼Œæ— ä»»ä½•æ¡çº¹çš„ä¸ºå°¾éƒ¨
"""

import cv2
import numpy as np
import os
from pathlib import Path
from typing import Tuple, Dict, List


class HeadTailDetector:
    """åœ†æŸ±ä½“é¦–å°¾æ£€æµ‹å™¨"""
    
    def __init__(self, reverse_logic: bool = False):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            reverse_logic: æ˜¯å¦åè½¬åˆ¤æ–­é€»è¾‘
                          False: é«˜åˆ†(å¤šçº¹ç†) = å¤´éƒ¨, ä½åˆ†(å…‰æ»‘) = å°¾éƒ¨
                          True:  ä½åˆ†(å…‰æ»‘) = å¤´éƒ¨, é«˜åˆ†(å¤šçº¹ç†) = å°¾éƒ¨  
        """
        self.min_edge_count = 50  # æœ€å°è¾¹ç¼˜ç‚¹æ•°é˜ˆå€¼
        self.reverse_logic = reverse_logic
    
    def detect_cylinder_region(self, gray: np.ndarray) -> Tuple[int, int, int, int]:
        """
        æ£€æµ‹åœ†æŸ±ä½“çš„å¤§è‡´ä½ç½®
        è¿”å›: (x, y, w, h) è¾¹ç•Œæ¡†
        """
        # ä½¿ç”¨OtsuäºŒå€¼åŒ–æ‰¾åˆ°ç‰©ä½“
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # å½¢æ€å­¦æ“ä½œå»å™ª
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=3)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ä¸­å¤®80%åŒºåŸŸ
            h, w = gray.shape
            margin_w = int(w * 0.1)
            margin_h = int(h * 0.1)
            return margin_w, margin_h, w - 2*margin_w, h - 2*margin_h
        
        # æ‰¾åˆ°æœ€å¤§è½®å»“
        max_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(max_contour)
        
        return x, y, w, h
    
    def extract_end_regions(self, image: np.ndarray, gray: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        æå–åœ†æŸ±ä½“ä¸¤ç«¯çš„æˆªé¢åŒºåŸŸ
        åŸºäºå›¾åƒä¸­åœ†æŸ±ä½“çš„å®é™…ä½ç½®
        """
        h, w = image.shape[:2]
        
        # æ£€æµ‹åœ†æŸ±ä½“ä½ç½®
        cx, cy, cw, ch = self.detect_cylinder_region(gray)
        
        # åˆ¤æ–­åœ†æŸ±ä½“åœ¨å›¾åƒä¸­çš„æœå‘
        # å¦‚æœåœ†æŸ±ä½“å®½åº¦ > é«˜åº¦ï¼Œè¯´æ˜æ˜¯æ°´å¹³æ”¾ç½®
        if cw > ch * 1.2:
            # æ°´å¹³æ”¾ç½®çš„åœ†æŸ±ä½“
            # æå–åœ†æŸ±ä½“å†…éƒ¨å·¦å³ä¸¤ä¾§çš„åŒºåŸŸ
            region_width = max(int(cw * 0.3), 50)  # æå–30%å®½åº¦åŒºåŸŸ
            
            # å·¦ä¾§æˆªé¢åŒºåŸŸ
            left_x = cx
            left_region = image[cy:cy+ch, left_x:left_x+region_width]
            left_gray = gray[cy:cy+ch, left_x:left_x+region_width]
            
            # å³ä¾§æˆªé¢åŒºåŸŸ  
            right_x = cx + cw - region_width
            right_region = image[cy:cy+ch, right_x:cx+cw]
            right_gray = gray[cy:cy+ch, right_x:cx+cw]
            
            return (left_region, left_gray), (right_region, right_gray)
        else:
            # å‚ç›´æ”¾ç½®çš„åœ†æŸ±ä½“
            # æå–åœ†æŸ±ä½“å†…éƒ¨ä¸Šä¸‹ä¸¤ä¾§çš„åŒºåŸŸ
            region_height = max(int(ch * 0.3), 50)  # æå–30%é«˜åº¦åŒºåŸŸ
            
            # ä¸Šä¾§æˆªé¢åŒºåŸŸ
            top_y = cy
            top_region = image[top_y:top_y+region_height, cx:cx+cw]
            top_gray = gray[top_y:top_y+region_height, cx:cx+cw]
            
            # ä¸‹ä¾§æˆªé¢åŒºåŸŸ
            bottom_y = cy + ch - region_height
            bottom_region = image[bottom_y:cy+ch, cx:cx+cw]
            bottom_gray = gray[bottom_y:cy+ch, cx:cx+cw]
            
            return (top_region, top_gray), (bottom_region, bottom_gray)
    
    def detect_patterns(self, gray: np.ndarray) -> Dict:
        """
        æ£€æµ‹å›¾åƒä¸­çš„æ¡çº¹/çº¹ç†ç‰¹å¾
        è¿”å›ï¼šè¾¹ç¼˜å¼ºåº¦ã€æ–¹å‘æ€§ã€çº¹ç†å¤æ‚åº¦ç­‰æŒ‡æ ‡
        """
        # 1. è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 30, 100)
        edge_count = np.sum(edges > 0)
        edge_density = edge_count / (gray.shape[0] * gray.shape[1])
        
        # 2. æ¢¯åº¦åˆ†æ
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
        avg_gradient = np.mean(gradient_magnitude)
        
        # 3. æ ‡å‡†å·®ï¼ˆçº¹ç†å¤æ‚åº¦ï¼‰
        std_dev = np.std(gray)
        
        # 4. é¢‘åŸŸåˆ†æï¼ˆæ£€æµ‹å‘¨æœŸæ€§æ¡çº¹ï¼‰
        f = np.fft.fft2(gray)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = np.abs(fshift)
        # è®¡ç®—é«˜é¢‘æˆåˆ†çš„èƒ½é‡
        h, w = magnitude_spectrum.shape
        center_h, center_w = h // 2, w // 2
        # å»é™¤ä¸­å¿ƒä½é¢‘éƒ¨åˆ†
        mask = np.ones((h, w), dtype=bool)
        mask[center_h-10:center_h+10, center_w-10:center_w+10] = False
        high_freq_energy = np.mean(magnitude_spectrum[mask])
        
        # 5. LBPï¼ˆå±€éƒ¨äºŒå€¼æ¨¡å¼ï¼‰- çº¹ç†ç‰¹å¾
        # ç®€åŒ–ç‰ˆï¼šè®¡ç®—åƒç´ å˜åŒ–é¢‘ç‡
        diff_x = np.abs(np.diff(gray.astype(np.float32), axis=1))
        diff_y = np.abs(np.diff(gray.astype(np.float32), axis=0))
        texture_variation = np.mean(diff_x) + np.mean(diff_y)
        
        return {
            'edge_count': edge_count,
            'edge_density': edge_density,
            'avg_gradient': avg_gradient,
            'std_dev': std_dev,
            'high_freq_energy': high_freq_energy,
            'texture_variation': texture_variation
        }
    
    def calculate_pattern_score(self, features: Dict) -> float:
        """
        è®¡ç®—æ¡çº¹/çº¹ç†å¾—åˆ†
        å¾—åˆ†è¶Šé«˜ï¼Œè¡¨ç¤ºæ¡çº¹è¶Šæ˜æ˜¾
        """
        # å„é¡¹ç‰¹å¾çš„æƒé‡
        score = 0.0
        
        # è¾¹ç¼˜å¯†åº¦ï¼ˆæ¡çº¹ä¼šæœ‰æ›´å¤šè¾¹ç¼˜ï¼‰
        score += features['edge_density'] * 1000
        
        # æ¢¯åº¦å¼ºåº¦ï¼ˆæ¡çº¹æœ‰æ˜æ˜¾çš„å¼ºåº¦å˜åŒ–ï¼‰
        score += features['avg_gradient'] * 0.5
        
        # æ ‡å‡†å·®ï¼ˆçº¹ç†å¤æ‚åº¦ï¼‰
        score += features['std_dev'] * 0.3
        
        # é«˜é¢‘èƒ½é‡ï¼ˆå‘¨æœŸæ€§æ¡çº¹ï¼‰
        score += features['high_freq_energy'] * 0.01
        
        # çº¹ç†å˜åŒ–
        score += features['texture_variation'] * 0.2
        
        return score
    
    def detect_ring_stripes(self, image: np.ndarray, gray: np.ndarray, cx: int, cy: int, radius: int) -> Dict:
        """
        æ£€æµ‹åœ†ç¯ä¸Šçš„æ¡çº¹ï¼ˆç”¨äºç«¯é¢è§†å›¾ï¼‰
        
        Args:
            image: åŸå§‹BGRå›¾åƒ
            gray: ç°åº¦å›¾åƒ
            cx, cy: åœ†å¿ƒåæ ‡
            radius: åœ†åŠå¾„
            
        Returns:
            åŒ…å«æ¡çº¹ä¿¡æ¯çš„å­—å…¸
        """
        # åˆ›å»ºç¯å½¢æ©ç ï¼ˆåªåŒ…å«çº¸ç­’å£å¤–è¡¨é¢åŒºåŸŸï¼Œæ’é™¤å†…éƒ¨ï¼‰
        h, w = gray.shape
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # å¤–åœ†åŠå¾„ï¼ˆç¨å¾®æ‰©å¤§ï¼‰
        outer_radius = int(radius * 1.02)
        # å†…åœ†åŠå¾„ï¼ˆå¢å¤§ä»¥åªä¿ç•™çº¸ç­’å£å¤–è¡¨é¢ï¼Œæ’é™¤å†…éƒ¨ç©ºæ´å’Œé˜´å½±ï¼‰
        inner_radius = int(radius * 0.85)
        
        # ç»˜åˆ¶ç¯å½¢æ©ç 
        cv2.circle(mask, (cx, cy), outer_radius, 255, -1)
        cv2.circle(mask, (cx, cy), inner_radius, 0, -1)
        
        # æå–ç¯å½¢åŒºåŸŸ
        ring_region = cv2.bitwise_and(image, image, mask=mask)
        
        # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´æ£€æµ‹å½©è‰²æ¡çº¹
        hsv = cv2.cvtColor(ring_region, cv2.COLOR_BGR2HSV)
        
        # å®šä¹‰æ¡çº¹é¢œè‰²èŒƒå›´ï¼ˆæ£€æµ‹å½©è‰²å’Œé»‘è‰²æ¡çº¹ï¼‰
        stripe_colors = {
            'yellow': {'lower': np.array([20, 80, 80]), 'upper': np.array([35, 255, 255])},
            'blue': {'lower': np.array([100, 80, 80]), 'upper': np.array([130, 255, 255])},
            'red': None,  # çº¢è‰²éœ€è¦ç‰¹æ®Šå¤„ç†
            'green': {'lower': np.array([40, 80, 80]), 'upper': np.array([80, 255, 255])},
            'black': {'lower': np.array([0, 0, 0]), 'upper': np.array([180, 100, 50])}  # æ·±é»‘è‰²æ¡çº¹
        }
        
        # è®¡ç®—ç¯å½¢åŒºåŸŸçš„æœ‰æ•ˆåƒç´ æ•°
        ring_pixels = np.sum(mask > 0)
        
        # æ£€æµ‹å„ç§é¢œè‰²
        color_percentages = {}
        for color_name, color_range in stripe_colors.items():
            if color_name == 'red':
                # çº¢è‰²è·¨è¶ŠHSVè‰²è½®
                mask1 = cv2.inRange(hsv, np.array([0, 80, 80]), np.array([10, 255, 255]))
                mask2 = cv2.inRange(hsv, np.array([170, 80, 80]), np.array([180, 255, 255]))
                color_mask = cv2.bitwise_or(mask1, mask2)
            else:
                color_mask = cv2.inRange(hsv, color_range['lower'], color_range['upper'])
            
            # åªåœ¨ç¯å½¢åŒºåŸŸå†…ç»Ÿè®¡
            color_mask = cv2.bitwise_and(color_mask, mask)
            color_pixels = np.sum(color_mask > 0)
            percentage = (color_pixels / ring_pixels) * 100 if ring_pixels > 0 else 0
            
            # å½©è‰²æ¡çº¹é˜ˆå€¼5%ï¼Œé»‘è‰²æ¡çº¹é˜ˆå€¼10%ï¼ˆåœ¨å¤–è¡¨é¢æ£€æµ‹æ›´ä¸¥æ ¼ï¼‰
            threshold = 10 if color_name == 'black' else 5
            if percentage > threshold:
                color_percentages[color_name] = percentage
        
        # åˆ¤æ–­æ˜¯å¦æœ‰æ¡çº¹
        has_stripes = len(color_percentages) > 0
        
        return {
            'has_stripes': has_stripes,
            'colors': color_percentages,
            'ring_mask': mask
        }
    
    def determine_head_tail(self, image: np.ndarray) -> Dict:
        """
        åˆ¤æ–­å›¾åƒä¸­åœ†æŸ±ä½“æˆªé¢æ˜¯HEADè¿˜æ˜¯TAIL
        åªåˆ†æä¸€ä¸ªæˆªé¢ï¼šæœ‰æ˜æ˜¾æ¡çº¹=HEADï¼Œæ— æ¡çº¹=TAIL
        """
        # é¢„å¤„ç†
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç«¯é¢è§†å›¾ï¼ˆåœ†å½¢ï¼‰
        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            dp=1,
            minDist=100,
            param1=50,
            param2=30,
            minRadius=30,
            maxRadius=min(gray.shape[0], gray.shape[1]) // 2
        )
        
        # å¦‚æœæ£€æµ‹åˆ°åœ†å½¢ï¼Œåˆ†æåœ†ç¯ä¸Šæ˜¯å¦æœ‰æ¡çº¹
        if circles is not None and len(circles[0]) > 0:
            # æ‰¾åˆ°æœ€å¤§çš„åœ†
            max_circle = max(circles[0], key=lambda c: c[2])
            cx, cy, radius = int(max_circle[0]), int(max_circle[1]), int(max_circle[2])
            
            # æ£€æŸ¥åœ†çš„å¤§å°æ˜¯å¦åˆç†
            min_image_dim = min(gray.shape[0], gray.shape[1])
            if radius > 50 and radius < min_image_dim * 0.4:
                # æ£€æµ‹åœ†ç¯ä¸Šçš„æ¡çº¹
                ring_info = self.detect_ring_stripes(image, gray, cx, cy, radius)
                
                if ring_info['has_stripes']:
                    # åœ†ç¯ä¸Šæœ‰å½©è‰²æ¡çº¹ â†’ HEAD
                    return {
                        'type': "HEAD",
                        'pattern_score': 100.0,
                        'confidence': 0.9,
                        'threshold': 50.0,
                        'features': {},
                        'cylinder_region': (0, 0, gray.shape[1], gray.shape[0]),
                        'is_end_view': True,
                        'circle_info': (cx, cy, radius),
                        'ring_colors': ring_info['colors']
                    }
                else:
                    # åœ†ç¯ä¸Šæ— æ¡çº¹ â†’ TAIL
                    return {
                        'type': "TAIL",
                        'pattern_score': 0.0,
                        'confidence': 0.9,
                        'threshold': 50.0,
                        'features': {},
                        'cylinder_region': (0, 0, gray.shape[1], gray.shape[0]),
                        'is_end_view': True,
                        'circle_info': (cx, cy, radius),
                        'ring_colors': {}
                    }
        
        # å¦‚æœä¸æ˜¯åœ†å½¢ï¼ŒæŒ‰ç…§åŸæ¥çš„ä¾§é¢è§†å›¾é€»è¾‘å¤„ç†
        # æ£€æµ‹åœ†æŸ±ä½“ä½ç½®
        cx, cy, cw, ch = self.detect_cylinder_region(gray)
        
        # æå–åœ†æŸ±ä½“æˆªé¢åŒºåŸŸï¼ˆæ•´ä¸ªåœ†æŸ±ä½“å†…éƒ¨åŒºåŸŸï¼‰
        cylinder_gray = gray[cy:cy+ch, cx:cx+cw]
        
        # æ£€æµ‹æ¡çº¹ç‰¹å¾
        features = self.detect_patterns(cylinder_gray)
        
        # è®¡ç®—æ¡çº¹å¾—åˆ†
        pattern_score = self.calculate_pattern_score(features)
        
        # åˆ¤æ–­æ˜¯HEADè¿˜æ˜¯TAIL
        # è®¾å®šé˜ˆå€¼ï¼šå¾—åˆ†è¶…è¿‡50è®¤ä¸ºæœ‰æ˜æ˜¾æ¡çº¹
        threshold = 50.0
        
        if pattern_score > threshold:
            # å¾—åˆ†é«˜ = æœ‰æ¡çº¹ = HEAD
            result_type = "HEAD"
            confidence = min((pattern_score - threshold) / threshold, 1.0)
        else:
            # å¾—åˆ†ä½ = æ— æ¡çº¹ = TAIL
            result_type = "TAIL"
            confidence = min((threshold - pattern_score) / threshold, 1.0)
        
        return {
            'type': result_type,
            'pattern_score': pattern_score,
            'confidence': confidence,
            'threshold': threshold,
            'features': features,
            'cylinder_region': (cx, cy, cw, ch),
            'is_end_view': False
        }
    
    def visualize(self, image: np.ndarray, result: Dict) -> np.ndarray:
        """
        å¯è§†åŒ–é¦–å°¾æ£€æµ‹ç»“æœ - åªæ˜¾ç¤ºHEADæˆ–TAILæ ‡ç­¾
        """
        vis_image = image.copy()
        h, w = vis_image.shape[:2]
        
        result_type = result['type']
        confidence = result['confidence']
        pattern_score = result['pattern_score']
        
        # å­—ä½“è®¾ç½® - æ›´å¤§æ›´é†’ç›®
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 3.0
        font_thickness = 8
        
        # æ˜¾ç¤ºHEADæˆ–TAILæ ‡ç­¾åœ¨å³ä¸Šè§’
        text = result_type
        (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
        
        # æ ¹æ®ç±»å‹é€‰æ‹©é¢œè‰²
        if result_type == "HEAD":
            bg_color = (0, 0, 255)  # çº¢è‰²
        else:
            bg_color = (0, 255, 0)  # ç»¿è‰²
        
        # æ˜¾ç¤ºåœ¨å³ä¸Šè§’
        cv2.rectangle(vis_image, (w-text_w-30, 10), (w-10, 30 + text_h), bg_color, -1)
        cv2.putText(vis_image, text, (w-text_w-20, 25 + text_h), 
                   font, font_scale, (255, 255, 255), font_thickness)
        
        # æ·»åŠ ç½®ä¿¡åº¦ä¿¡æ¯
        info_texts = [
            f"Type: {result['type']}",
            f"Pattern Score: {result['pattern_score']:.1f}",
            f"Threshold: {result['threshold']:.1f}",
            f"Confidence: {result['confidence']:.2%}"
        ]
        
        text_y = h - 150
        for text in info_texts:
            (text_width, text_height), baseline = cv2.getTextSize(
                text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            cv2.rectangle(vis_image, (5, text_y - text_height - 5), 
                         (15 + text_width, text_y + baseline), (0, 0, 0), -1)
            cv2.putText(vis_image, text, (10, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            text_y += 35
        
        return vis_image


def process_head_tail_batch(input_dir: str = "data/input_is_head", 
                            output_dir: str = "data/output/head",
                            reverse_logic: bool = False):
    """
    æ‰¹é‡å¤„ç†é¦–å°¾æ£€æµ‹
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•  
        reverse_logic: æ˜¯å¦åè½¬åˆ¤æ–­é€»è¾‘ï¼ˆFalse=æœ‰çº¹ç†ä¸ºå¤´éƒ¨ï¼Œé»˜è®¤ï¼‰
    """
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰
    image_files = []
    input_path = Path(input_dir)
    
    for ext in image_extensions:
        image_files.extend(input_path.rglob(f"*{ext}"))
        image_files.extend(input_path.rglob(f"*{ext.upper()}"))
    
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    print("=" * 70)
    
    # åˆ›å»ºæ£€æµ‹å™¨ï¼ˆä½¿ç”¨åè½¬é€»è¾‘ï¼‰
    detector = HeadTailDetector(reverse_logic=reverse_logic)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    results = []
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for idx, image_path in enumerate(image_files, 1):
        print(f"\n[{idx}/{len(image_files)}] å¤„ç†: {image_path.name}")
        
        # è¯»å–å›¾åƒï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
        image = cv2.imdecode(np.fromfile(str(image_path), dtype=np.uint8), 
                            cv2.IMREAD_COLOR)
        
        if image is None:
            print(f"   âŒ æ— æ³•è¯»å–å›¾åƒ")
            continue
        
        # æ£€æµ‹é¦–å°¾
        result = detector.determine_head_tail(image)
        
        # å¯è§†åŒ–
        visualized = detector.visualize(image, result)
        
        # ä¿å­˜ç»“æœ
        output_path = os.path.join(output_dir, 
                                  f"{image_path.stem}_head_tail.jpg")
        is_success, buffer = cv2.imencode('.jpg', visualized)
        if is_success:
            buffer.tofile(output_path)
        
        # æ‰“å°ç»“æœ
        print(f"   âœ… ç±»å‹: {result['type']}")
        print(f"   ğŸ“Š æ¡çº¹å¾—åˆ†: {result['pattern_score']:.1f}")
        print(f"   ğŸ“ é˜ˆå€¼: {result['threshold']:.1f}")
        print(f"   ğŸ“ˆ ç½®ä¿¡åº¦: {result['confidence']:.2%}")
        
        # ä¿å­˜åˆ°ç»“æœåˆ—è¡¨
        results.append({
            'file': image_path.name,
            'subfolder': image_path.parent.name,
            'type': result['type'],
            'pattern_score': result['pattern_score'],
            'threshold': result['threshold'],
            'confidence': result['confidence']
        })
    
    print("\n" + "=" * 70)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ! å…±å¤„ç† {len(results)} å¼ å›¾åƒ")
    print(f"ğŸ’¾ ç»“æœä¿å­˜åœ¨: {output_dir}")
    
    # ä¿å­˜CSVæŠ¥å‘Š
    if results:
        csv_path = os.path.join(output_dir, "head_tail_report.csv")
        with open(csv_path, 'w', encoding='utf-8-sig') as f:
            f.write("æ–‡ä»¶å,å­ç›®å½•,ç±»å‹,æ¡çº¹å¾—åˆ†,é˜ˆå€¼,ç½®ä¿¡åº¦\n")
            for r in results:
                f.write(f"{r['file']},{r['subfolder']},{r['type']},"
                       f"{r['pattern_score']:.2f},{r['threshold']:.2f},"
                       f"{r['confidence']:.4f}\n")
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {csv_path}")


def process_single_head_tail(image_path: str, output_dir: str = "data/output/head",
                            reverse_logic: bool = False):
    """å¤„ç†å•å¼ å›¾åƒçš„é¦–å°¾æ£€æµ‹
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        reverse_logic: æ˜¯å¦åè½¬åˆ¤æ–­é€»è¾‘ï¼ˆFalse=æœ‰çº¹ç†ä¸ºå¤´éƒ¨ï¼Œé»˜è®¤ï¼‰
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # è¯»å–å›¾åƒï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), 
                        cv2.IMREAD_COLOR)
    
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return None
    
    print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")
    print(f"   å›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = HeadTailDetector(reverse_logic=reverse_logic)
    
    # æ£€æµ‹é¦–å°¾
    result = detector.determine_head_tail(image)
    
    # å¯è§†åŒ–
    visualized = detector.visualize(image, result)
    
    # æ‰“å°æ£€æµ‹ä¿¡æ¯
    print(f"   âœ… æ£€æµ‹æˆåŠŸ!")
    print(f"   ğŸ” ç±»å‹: {result['type']}")
    print(f"   ğŸ“Š æ¡çº¹å¾—åˆ†: {result['pattern_score']:.1f}")
    print(f"   ğŸ“ é˜ˆå€¼: {result['threshold']:.1f}")
    print(f"   ğŸ“ˆ ç½®ä¿¡åº¦: {result['confidence']:.2%}")
    
    # ä¿å­˜ç»“æœ
    filename = os.path.splitext(os.path.basename(image_path))[0]
    output_path = os.path.join(output_dir, f"{filename}_head_tail.jpg")
    
    is_success, buffer = cv2.imencode('.jpg', visualized)
    if is_success:
        buffer.tofile(output_path)
        print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æ˜¾ç¤ºç»“æœ
    display_height = 800
    aspect_ratio = image.shape[1] / image.shape[0]
    display_width = int(display_height * aspect_ratio)
    
    display_image = cv2.resize(visualized, (display_width, display_height))
    cv2.imshow("Head-Tail Detection (Press any key to close)", display_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    return result


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("=" * 70)
        print("ğŸ” åœ†æŸ±ä½“é¦–å°¾æ£€æµ‹å·¥å…·")
        print("=" * 70)
        print("\nåŠŸèƒ½è¯´æ˜:")
        print("  æ ¹æ®ä¸¤ç«¯æˆªé¢çš„æ¡çº¹ç‰¹å¾åˆ¤æ–­åœ†æŸ±ä½“çš„é¦–å°¾")
        print("  - å­˜åœ¨æ˜æ˜¾æ¡çº¹çš„ä¸ºå¤´éƒ¨")
        print("  - æ— ä»»ä½•æ¡çº¹çš„ä¸ºå°¾éƒ¨")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python head_tail_detector.py <image_path>      # å¤„ç†å•å¼ å›¾åƒ")
        print("  python head_tail_detector.py --batch           # æ‰¹é‡å¤„ç†")
        print("\nç¤ºä¾‹:")
        print("  python head_tail_detector.py \"data/input_is_head/1/h (1).jpg\"")
        print("  python head_tail_detector.py --batch")
    elif sys.argv[1] == "--batch" or sys.argv[1] == "-b":
        process_head_tail_batch()
    else:
        process_single_head_tail(sys.argv[1])
